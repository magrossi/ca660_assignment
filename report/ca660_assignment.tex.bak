\documentclass{article}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\usepackage{natbib}
\bibliographystyle{IEEEtranN}
\title{Forecasting House Prices in Ireland}
\author{Grossi, M. \and Y. Xuan}
\begin{document}
\maketitle
\begin{abstract}
Widely attributed as the cause of the global market crisis of 2007, the house pricing bubble is an important topic of research. Economists try to explain what causes changes in house prices to understand and create policies that will affect this market (\citep{unknown2010} and \citep{winter2003}).
\par
This project aims to forecast the prices of new houses in Ireland based on available statistical data sets that from a fundamental economic standpoint (\citep{gert2007}) might influence the housing market (\citep{toby2014}). Four fundamentally sensitive data sets are chosen of an initial group to serve as predictors. An ARIMA model is then fitted to our data and a forecast of the prices of new houses in Ireland is produced with satisfactory results.
\end{abstract}
\section{Introduction}
After a five-year housing bust, Ireland?s house prices are now rising sharply. The national residential property price index skyrocketed by 16.2\% (16.1\% inflation-adjusted) y-o-y in November 2014, a sharp improvement from the annual rise of 5.6\% a year earlier and a contraction of 5.7\% in November 2012, according to Central Statistics Office Ireland. During the latest quarter, nationwide house prices rose sharply by 5.3\% (6.2\% inflation-adjusted).\footnote{Global Property Guide, http://www.globalpropertyguide.com}
\par
In this report, an effort is made to forecast the house price in Ireland for the 2-5 future years, meanwhile, based on the data before 2007, a prediction for 2008-2011 would be compared to the existing data, to study how much the crisis influenced the house pricing mathematically, and to verify the accuracy of our prediction according to the real data. 
\par
This prediction is based on the time series analysis, with R\footnote{A programming language for Statistical Computing} and various time series and statistical packages\footnote{pxR, tseries, forecast package} are used along with other standard packages as the statistical software. Time series decomposition is to decompose a time series into trend, seasonal, cyclical and irregular components, which is also a sequence of data points, typically consisting of successive measurements made over a time interval. For the analysis, which comprises methods for analysing time series data in order to extract meaningful statistics and other characteristics of the data.\footnote{Wikipedia, https://en.wikipedia.org/wiki/Time\_series} 
\par
We built our prediction model according to the ARIMA\footnote{Autoregressive Integrated Moving Average} model, which is itted to time series data either to better understand the data or to predict future points in the series (forecasting). They are applied in some cases where data show evidence of non-stationarity, where an initial differencing step (corresponding to the "integrated" part of the model) can be applied to reduce the non-stationarity. For house price forecasting this model assumes and takes into account the non-zero autocorrelation between the successive values of the time series data, and considering other datasets we used for this model, such as population and GDP, this model would also involve them. The goal of this effort is to use the Box-Jenkins time series, including exogenous predictors is called a dynamic regression model, and special care must be taken to ensure that the internal dynamics of each exogenous predictor is not confounded with the dynamics of any other predictor. 
\par
When there are multiple exogenous predictors (Population, GDP, House completions), that influence a response variable, the house price, the same steps must be followed for the case in which there is only one predictor. Each exogenous predictor is a time series in itself that must be calculated independently of the others so that the identification of the house price response can be performed in the presence of the other data. Once the response model has been identified, the estimation and forecasting steps follow directly.
\section{The Data}
To be written...
\section{Study: A Time Series Analysis}
Time series analysis is a very large research topic given its large usability in a multitude of environments and several methods for analysing such data exists (\citep{cowpertwait2009introductory} and \citep{Coghlan2015}), which gives a researcher an ample choice of approaches to work with. That is why it is of paramount importance that an appropriate model is chosen.
\subsection{Model choice}
The choice of a model depends entirely on the characteristics of the data we are trying to forecast and whether the data appears to be random or not (\citep{Kumar2014}). If a time series is random then it is expected that the correlations between its successive values is close to zero. If it is discovered that there exists a correlation between the consecutive observations of a time series than an autoregressive model is likely to be a good choice as it has the ability to cope with such dependencies.\par
For this project we chose the autoregressive integrated moving average or \(ARIMA(p,d,q)\) model for its ability to take into consideration not only the autoregressive nature of the data, but also can cope well with non-stationary, seasonal time series. Given the available data for our project is yearly, we will not be evaluating any seasonal component and it will not influence the results as the model is built for both seasonal and non-seasonal time series. The full equation of the \(ARIMA(p,d,q)\) without any explanatory variables.
\[ARIMA(p,d,q) = \mu + \phi_1 y_{t-1} + ... + \phi_p y_{t-p} - \theta_1 e_{t-1} - ... - \theta_q e_{t-q} \]
\par
According to \citep{hyndman2014forecasting} we can introduce the explanatory variables by letting the error \(e\) be autocorrelated. This can be expressed by the backshift notation (\(B^dy = y_{t-d}\)) example \(ARIMA(1,1,1)\) equation below, where \(x_{1,t}\) to \(x_{k,t}\) are our explanatory variables (\(cna13\), \(hsa01\), \(hsa08\) and \(gdp\)).
\[y_t = \beta_0 + \beta_1x_{1,t} + ... + \beta_kx_{k,t} + n_t,\]
\[(1-\phi_1B)(1-B)n_t=(1+\chi_1B)e_t,\]
where \(e_t\) is white noise.
\subsection{Model Parameters}
The \(p\), \(d\) and \(q\) parameters must be chosen for the \(ARIMA(p,d,q)\) model. Parameter \(p\) is the coefficient of the auto regressive part, \(d\) is the integration order (or the number of differences that make our time series stationary) and \(q\) is the coefficient for the moving average. In this project we use the \citep{Hyndman2008} algorithm that traverses the model space and tries to minimize the corrected Akaike’s Information Criterion (\(AIC_c\)) value in a two-step approach. \par
First step is to initialize the model with \(ARIMA(p,d,q)\) and choose the one with minimum \(AIC_c\), where \(d\) is determined by unit root tests and \((p,q) \in [(2,2), (0,0), (1,0),(0,1)]\). The second step will vary the chosen \(p\) and \(q\) by \(\pm1\) until no smaller \(AIC_c\) value can be found. For this project the optimal model was found to be \(ARIMA(3,0,0)\)\footnote{The model is equivalent to an \(AR(3)\) model.} and the coefficients can be seen in Table ~\ref{tab:arimaCoeff}.
\par
\begin{table}[H]
  \footnotesize
  \centering
  \begin{tabular}{r l l l l l l l l}
  & \(AR^1\) & \(AR^2\) & \(AR^3\) & Intercept & cna13 & hsa01 & hsa08 & gdp \\ \hline
  Coeff. & 0.8548 & -0.0684 & -0.4110 & -0.1414 & 0.8269 & 0.1994 & 0.0732 & 0.5243 \\ 
  s.e. & 0.1754 & 0.2365 & 0.1655 & 0.0302 & 0.1960 & 0.0402 & 0.0306 & 0.0712 \\ \hline
  \multicolumn{9}{l}{est.\(\sigma^2\)=4.613e-05, log likelihood=109.85, \(AIC=-201.7, AIC_c=-193.12, BIC=-188.79\)}\\
  \end{tabular}
  \caption{Table of \(ARIMA(3,0,0)\) coefficients with non-zero mean}
  \label{tab:arimaCoeff}
\end{table}
\subsection{Model fitting and forecasting}
After determining the optimal model parameters we must fit the model from our data. For this project we have split our data set into two; one for training and another for testing our forecast. Considering that the available data period for the Irish prices of new houses varies from 1975 to 2013 we have chosen 1975 to 2005 as the training set and from 2006 to 2011\footnote{As the predictor data sets only go up to 2011 we must limit this data set as well.} as the testing data set.
\par
The fitted model is now used to forecast the future values of the Irish new house prices from 2006 to 2011. Table ~\ref{tab:forecast} shows the forecast raw values and Figure ~\ref{fig:forecast} the graphical comparison of the real values versus the forecast values.
\par
\begin{table}[H]
  \centering
  \begin{tabular}{l|l l|l l l l}
Year & Forecast & Real & Lo 80 & Lo 95 & Hi 80 & Hi 95 \\ \hline
2006 & 304,660.80 & 305,637.00 & 301,967.70 & 300,542.20 & 307,353.80 & 308,779.40 \\
2007 & 303,497.10 & 322,634.00& 299,954.30 & 298,078.90 & 307,039.80 & 308,915.20 \\
2008 & 273,847.30 & 305,269.00& 269,881.10 & 267,781.50 & 277,813.50 & 279,913.10 \\
2009 & 237,711.60 & 242,033.00& 233,736.90 & 231,632.80 & 241,686.40 & 243,790.50 \\
2010 & 228,514.20 & 228,268.00& 224,450.40 & 222,299.20 & 232,578.00 & 234,729.20 \\
2011 & 233,964.90 & 230,303.00& 229,642.20 & 227,353.80 & 238,287.70 & 240,576.10 \\
  \end{tabular}
  \caption{Table of scaled prices of new Irish houses}
  \label{tab:forecast}
\end{table}
\begin{figure}[!ht]
\includegraphics[width=\textwidth,height=\textheight,keepaspectratio,natwidth=682,natheight=544]{forecast.jpeg}
\caption{Real prices for new Irish houses versus forecast prices.}
\label{fig:forecast}
\end{figure}
\par
The visual comparison of the forecast values versus the real values is very satisfying but we must also analyse the forecasts residuals. It is desired that the residual errors of a forecast be normally distributed with zero mean and constant variance and have no correlation between successive forecast errors. This is to ensure that the residuals are just noise and do not hide any unexplained variables which would indicate a poor forecast model.
\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\linewidth,keepaspectratio,natwidth=682,natheight=544]{residuals.jpeg}
\caption{Forecast residuals errors, autocorrelation and partial autocorrelation.}
\label{fig:residuals}
\end{figure}
\begin{figure}[!ht]
\centering
\includegraphics[width=0.7\linewidth,keepaspectratio,natwidth=682,natheight=544]{normal.jpeg}
\caption{Normal Q-Q plot of forecast residuals.}
\label{fig:normal}
\end{figure}
\par
Analysing Figure ~\ref{fig:residuals} we can see that there are no correlated lagged errors and Figure ~\ref{fig:normal} shows a compatible normal distribution and finally we run a Box-Ljung test that fails to reject our null hypothesis that there are no autocorrelations in the forecast errors at the first \(10\) lags (Table ~\ref{tab:boxtest}).
 \begin{table}[H]
  \centering
  \begin{tabular}{ccc}
\(\chi^2\) & df & p-value \\ \hline
7.6182 & 10 & 0.6661 \\
  \end{tabular}
  \caption{Table of Box-Ljung test results for \(H_o\): No autocorrelations}
  \label{tab:boxtest}
\end{table}
\section{Conclusions}
This project showed how to apply an autoregressive \(ARIMA\) model to a time series using four fundamentally reasonable external predictors to forecast the prices of new houses in Ireland. It is shown that a model of \(ARIMA(3,0,0)\) was a good fit for our data and the forecast residuals showed no autocorrelation and that they seem to follow a normal distribution with mean zero and constant variance.
\par
The forecast value of the house prices was then compared to their real value and the result was very satisfactory. Considering that the period for which the forecast was ran coincided with the “property market bubble burst” of 2006 to 2008 and the model was able to pick up these abrupt changes makes the results more gratifying.
\par
It would be beneficial for future work to repeat this study with monthly data, instead of yearly (provided this data is available). This would allow exploring the seasonality of the data, which from an economically fundamental point of view would make sense given that house prices may be impacted by holiday season and perhaps end of year, when people usually have more expenditures and are less likely to be looking to buy.
\par
Another avenue of research would be to compare several time series analysis methods on the same data set. For our example we could improve upon this work by trying \(VAR\) and \(GARCH\) models for example.
\bibliography{ca660_assignment}
\end{document}